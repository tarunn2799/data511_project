{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data from Job Postings - Data Cleaning\n",
    "\n",
    "## Data Set Structure\n",
    "\n",
    "1. Year - Taken from manually from the file name.\n",
    "\n",
    "2. Job Type - Best to call openAI API and classify the job titles into 5 categories that we have defined.\n",
    "    - ML Engineer\n",
    "    - Data Analyst\n",
    "    - Data Engineer\n",
    "    - Data Science\n",
    "    - Applied Reaserch \n",
    "\n",
    "        \n",
    "2. Industry - The classifier below matches job description to industry (Predefined set of 67).\n",
    "    - https://huggingface.co/sampathkethineedi/industry-classification\n",
    "\n",
    "    \n",
    "3. Technical Skills - for example data cleaning, feature engineering, etc.\n",
    "    - https://huggingface.co/algiraldohe/lm-ner-linkedin-skills-recognition\n",
    "    - The model works pretty well, has skill types\n",
    "    - Doing this through OpenAI sounds like pain but idk\n",
    "\n",
    "\n",
    "4. Technology skills - Python, SQL, Java, etc.\n",
    "    - Same classification method as for Technical skills\n",
    "\n",
    "\n",
    "5. Soft Skills - fast learner, bla bla bla corpo talk, etc.\n",
    "    - Same classification as for Technology and Technical skills.\n",
    "\n",
    "\n",
    "6. Salary \n",
    "    - Could use chatGPT for this, have not found a ready made solution. Prompting for this might be a pain since in my opinion ChatGPT is terrible with numbers.\n",
    "\n",
    "\n",
    "7. Company Name\n",
    "    - What if in one dataset we have Microsoft and in other Microsoft, inc?\n",
    "\n",
    "7. Education\n",
    "    - I am doing a regex matching function\n",
    "\n",
    "8. Years of experience\n",
    "    - Use OpenAi idk how to do it otherwise\n",
    "\n",
    "\n",
    "9. City\n",
    "    - https://huggingface.co/ml6team/bert-base-uncased-city-country-ner?text=Sunnyvale\n",
    "    - 2023 dataset does not have this\n",
    "\n",
    "\n",
    "10. State\n",
    "    - 2023 dataset does not have this\n",
    "    \n",
    "\n",
    "# PLZ review and see what else is needed\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To run the code below make sure you have pyTorch and TensorFlow installed\n",
    "\n",
    "`pip3 install torch torchvision torchaudio`\n",
    "\n",
    "`pip install tensorflow `\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from transformers import pipeline\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40f553f68414c6fa58ea2e3f382536f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0730bdc929c42c597e5a420ddef5694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/266M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88011d36039a4487af535686184e0a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/320 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "551021c129e841abb7eeffc10b8c95f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23c304da297d46f88916e4fb453ea5dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864da64c18c24625a6c1313241b98d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Skill Extraction\n",
    "extract_skills = pipeline(\"token-classification\", model=\"algiraldohe/lm-ner-linkedin-skills-recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Industry Classification\n",
    "get_industry = pipeline(\"text-classification\", model=\"sampathkethineedi/industry-classification-api\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57b454bdfbc42e2a178e07bcb69ff87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/849 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2b302f3dbb4c719498ecdbb275ec26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c100b725214374a5447291c4b47eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/348 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1cb09dab2f4d4e8386937185de3d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3810ffca65854ed185278921472d54da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0bcc37c3134d98bcf99137caa35e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "get_city = pipeline(\"token-classification\", model=\"ml6team/bert-base-uncased-city-country-ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is wrong, if you input \"Atlanta, GA\", it will give you [LA, GA]\n",
    "def find_state_codes(input_string):\n",
    "    state_code_pattern = \"([Aa][EeLlKkSsZzRr]|[Cc][AaOoTt]|[Dd][EeCc]|[Ff][MmLl]|[Gg][AaUu]|[Hh][Ii]|[Ii][DdLlNnAa]|[Kk][SsYy]|[Ll][Aa]|[Mm][EeHhDdAaIiNnSsOoTt]|[Nn][EeVvHhJjMmYyCcDd]|[Mm][Pp]|[Oo][HhKkRr]|[Pp][WwAaRr]|[Rr][Ii]|[Ss][CcDd]|[Tt][NnXx]|[Uu][Tt]|[Vv][TtIiAa]|[Ww][AaVvIiYy])\"\n",
    "    matches = re.findall(state_code_pattern, input_string, flags=re.IGNORECASE)\n",
    "    return [match.upper() for match in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Degree Matching\n",
    "\n",
    "def needs_bachelors_degree(job_posting):\n",
    "    degree_keywords = ['Bachelor', 'BA', 'BS', 'BSc', 'B.A.', 'B.S.', 'B.Sc.', 'Undergraduate', 'AB', 'S.B.', 'SB', 'BEng', 'BFA', 'BBA', 'LLB', 'BCom', 'BEd', 'BMath', 'BArch', 'B.Tech', 'B.Des', 'B.Pharm', 'B.Nursing', 'B.HSc', 'B.IT', 'B.Econ']\n",
    "\n",
    "    degree_pattern = re.compile(r'\\b(?:' + '|'.join(degree_keywords) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "    return bool(degree_pattern.search(job_posting))\n",
    "\n",
    "def needs_masters_degree(job_posting):\n",
    "    degree_keywords = ['Master', 'MS', 'MSc', 'M.A.', 'M.S.', 'M.Sc.', 'Graduate', 'MA', 'MEng', 'MFA', 'MBA', 'LLM', 'MCom', 'MEd', 'MPhil', 'MRes', 'MArch', 'M.Tech', 'M.Des', 'M.Pharm', 'M.Nursing', 'M.HSc', 'M.IT', 'M.Econ']\n",
    "\n",
    "    degree_pattern = re.compile(r'\\b(?:' + '|'.join(degree_keywords) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "    return bool(degree_pattern.search(job_posting))\n",
    "\n",
    "def needs_phd(job_posting):\n",
    "    degree_keywords = ['PhD', 'Doctorate', 'Doctoral', 'Ph.D.', 'D.Phil', 'Dr.', 'DSc', 'DLitt', 'ThD', 'D.Tech', 'PharmD', 'ScD', 'EdD']\n",
    "\n",
    "    degree_pattern = re.compile(r'\\b(?:' + '|'.join(degree_keywords) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "    return bool(degree_pattern.search(job_posting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data set 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>position</th>\n",
       "      <th>company</th>\n",
       "      <th>description</th>\n",
       "      <th>reviews</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Development Director</td>\n",
       "      <td>ALS TDI</td>\n",
       "      <td>Development Director\\nALS Therapy Development ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta, GA 30301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An Ostentatiously-Excitable Principal Research...</td>\n",
       "      <td>The Hexagon Lavish</td>\n",
       "      <td>Job Description\\n\\n\"The road that leads to acc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Xpert Staffing</td>\n",
       "      <td>Growing company located in the Atlanta, GA are...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Operation HOPE</td>\n",
       "      <td>DEPARTMENT: Program OperationsPOSITION LOCATIO...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Atlanta, GA 30303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assistant Professor -TT - Signal Processing &amp; ...</td>\n",
       "      <td>Emory University</td>\n",
       "      <td>DESCRIPTION\\nThe Emory University Department o...</td>\n",
       "      <td>550.0</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6959</th>\n",
       "      <td>Data Developer / Machine Learning Analyst</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Are you data-driven? We at NetApp believe in t...</td>\n",
       "      <td>574.0</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6960</th>\n",
       "      <td>Scientist I</td>\n",
       "      <td>Pharmacyclics, an Abbvie Company</td>\n",
       "      <td>Pharmacyclics is committed to the development ...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6961</th>\n",
       "      <td>Intern Scientist</td>\n",
       "      <td>Oath Inc</td>\n",
       "      <td>Oath, a subsidiary of Verizon, is a values-led...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6962</th>\n",
       "      <td>Senior Data &amp; Applied Scientist</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>We are the Bing Core Relevance team responsibl...</td>\n",
       "      <td>4618.0</td>\n",
       "      <td>Sunnyvale, CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6963</th>\n",
       "      <td>Principal Data Scientist, Deep Learning</td>\n",
       "      <td>Comcast</td>\n",
       "      <td>Comcast’s Technology &amp;amp; Product organizatio...</td>\n",
       "      <td>11610.0</td>\n",
       "      <td>Sunnyvale, CA 94089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6964 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               position  \\\n",
       "0                                  Development Director   \n",
       "1     An Ostentatiously-Excitable Principal Research...   \n",
       "2                                        Data Scientist   \n",
       "3                                          Data Analyst   \n",
       "4     Assistant Professor -TT - Signal Processing & ...   \n",
       "...                                                 ...   \n",
       "6959          Data Developer / Machine Learning Analyst   \n",
       "6960                                        Scientist I   \n",
       "6961                                   Intern Scientist   \n",
       "6962                    Senior Data & Applied Scientist   \n",
       "6963            Principal Data Scientist, Deep Learning   \n",
       "\n",
       "                               company  \\\n",
       "0                              ALS TDI   \n",
       "1                   The Hexagon Lavish   \n",
       "2                       Xpert Staffing   \n",
       "3                       Operation HOPE   \n",
       "4                     Emory University   \n",
       "...                                ...   \n",
       "6959                            NetApp   \n",
       "6960  Pharmacyclics, an Abbvie Company   \n",
       "6961                          Oath Inc   \n",
       "6962                         Microsoft   \n",
       "6963                           Comcast   \n",
       "\n",
       "                                            description  reviews  \\\n",
       "0     Development Director\\nALS Therapy Development ...      NaN   \n",
       "1     Job Description\\n\\n\"The road that leads to acc...      NaN   \n",
       "2     Growing company located in the Atlanta, GA are...      NaN   \n",
       "3     DEPARTMENT: Program OperationsPOSITION LOCATIO...     44.0   \n",
       "4     DESCRIPTION\\nThe Emory University Department o...    550.0   \n",
       "...                                                 ...      ...   \n",
       "6959  Are you data-driven? We at NetApp believe in t...    574.0   \n",
       "6960  Pharmacyclics is committed to the development ...     26.0   \n",
       "6961  Oath, a subsidiary of Verizon, is a values-led...      5.0   \n",
       "6962  We are the Bing Core Relevance team responsibl...   4618.0   \n",
       "6963  Comcast’s Technology &amp; Product organizatio...  11610.0   \n",
       "\n",
       "                 location  \n",
       "0      Atlanta, GA 30301   \n",
       "1             Atlanta, GA  \n",
       "2             Atlanta, GA  \n",
       "3      Atlanta, GA 30303   \n",
       "4             Atlanta, GA  \n",
       "...                   ...  \n",
       "6959        Sunnyvale, CA  \n",
       "6960        Sunnyvale, CA  \n",
       "6961        Sunnyvale, CA  \n",
       "6962        Sunnyvale, CA  \n",
       "6963  Sunnyvale, CA 94089  \n",
       "\n",
       "[6964 rows x 5 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in Data set\n",
    "\n",
    "csv_file_path = 'path/to/your/file.csv'\n",
    "\n",
    "df2019 = pd.read_csv('job_posting_data/Data_Jobs_2019.csv')\n",
    "\n",
    "df2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'CITY', 'score': 0.9728621, 'index': 1, 'word': 'atlanta', 'start': 0, 'end': 7}]\n",
      "[{'entity': 'CITY', 'score': 0.9683732, 'index': 1, 'word': 'atlanta', 'start': 0, 'end': 7}]\n",
      "[{'entity': 'CITY', 'score': 0.9683732, 'index': 1, 'word': 'atlanta', 'start': 0, 'end': 7}]\n",
      "[{'entity': 'CITY', 'score': 0.97546536, 'index': 1, 'word': 'atlanta', 'start': 0, 'end': 7}]\n",
      "[{'entity': 'CITY', 'score': 0.9683732, 'index': 1, 'word': 'atlanta', 'start': 0, 'end': 7}]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Skills</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Development Director</td>\n",
       "      <td>ALS TDI</td>\n",
       "      <td>Development Director\\nALS Therapy Development ...</td>\n",
       "      <td>Atlanta, GA 30301</td>\n",
       "      <td>Health Care Services</td>\n",
       "      <td>0</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An Ostentatiously-Excitable Principal Research...</td>\n",
       "      <td>The Hexagon Lavish</td>\n",
       "      <td>Job Description\\n\\n\"The road that leads to acc...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Human Resource &amp; Employment Services</td>\n",
       "      <td>0</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Xpert Staffing</td>\n",
       "      <td>Growing company located in the Atlanta, GA are...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Life Sciences Tools &amp; Services</td>\n",
       "      <td>0</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Operation HOPE</td>\n",
       "      <td>DEPARTMENT: Program OperationsPOSITION LOCATIO...</td>\n",
       "      <td>Atlanta, GA 30303</td>\n",
       "      <td>Environmental &amp; Facilities Services</td>\n",
       "      <td>0</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assistant Professor -TT - Signal Processing &amp; ...</td>\n",
       "      <td>Emory University</td>\n",
       "      <td>DESCRIPTION\\nThe Emory University Department o...</td>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>Life Sciences Tools &amp; Services</td>\n",
       "      <td>0</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Type        Company Name  \\\n",
       "0                               Development Director             ALS TDI   \n",
       "1  An Ostentatiously-Excitable Principal Research...  The Hexagon Lavish   \n",
       "2                                     Data Scientist      Xpert Staffing   \n",
       "3                                       Data Analyst      Operation HOPE   \n",
       "4  Assistant Professor -TT - Signal Processing & ...    Emory University   \n",
       "\n",
       "                                         description            location  \\\n",
       "0  Development Director\\nALS Therapy Development ...  Atlanta, GA 30301    \n",
       "1  Job Description\\n\\n\"The road that leads to acc...         Atlanta, GA   \n",
       "2  Growing company located in the Atlanta, GA are...         Atlanta, GA   \n",
       "3  DEPARTMENT: Program OperationsPOSITION LOCATIO...  Atlanta, GA 30303    \n",
       "4  DESCRIPTION\\nThe Emory University Department o...         Atlanta, GA   \n",
       "\n",
       "                               Industry  Skills     City  \n",
       "0                  Health Care Services       0  Atlanta  \n",
       "1  Human Resource & Employment Services       0  Atlanta  \n",
       "2        Life Sciences Tools & Services       0  Atlanta  \n",
       "3   Environmental & Facilities Services       0  Atlanta  \n",
       "4        Life Sciences Tools & Services       0  Atlanta  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This dataset took like 5 minutes on my computer to process so if you want to see what processing does uncomment line below\n",
    "df2019 = df2019.head()\n",
    "\n",
    "df2019 = df2019.drop('reviews', axis=1)\n",
    "df2019.rename(columns={'position': 'Job Type'}, inplace=True)\n",
    "df2019.rename(columns={'company': 'Company Name'}, inplace=True)\n",
    "\n",
    "def getIndustryFromDesc(x):\n",
    "    if type(x) == str: #some job description was a float \n",
    "        industry_classification = get_industry(x[0:512]) #some pytorch function only allows strings up to 512 chars, but industry is always mentioned first so we good;\n",
    "        return industry_classification[0].get(\"label\"); # do we wanna check confidence intervals or fuck it?\n",
    "    else:\n",
    "       return ''\n",
    "\n",
    "df2019['Industry'] = df2019['description'].apply(getIndustryFromDesc)\n",
    "\n",
    "##TODO write a function so skills can be extracted correctly\n",
    "def getSkillsFromDesc(x):\n",
    "    dupa = extract_skills(x[0:512]) #TODO batch processing strings are limited to 512 chars\n",
    "    #print(dupa)\n",
    "    return 0 # you want to return skills based on category, b-bus, b-technical, the link is above in markdown\n",
    "\n",
    "df2019['Skills'] = df2019['description'].apply(getSkillsFromDesc)\n",
    "\n",
    "def getCityFromLocation(x):\n",
    "    y = get_city(x);\n",
    "    print(y);\n",
    "    city = y[0].get('word');\n",
    "    return city[0].upper() + city[1:];\n",
    "\n",
    "df2019['City'] = df2019['location'].apply(getCityFromLocation)\n",
    "\n",
    "df2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'your_csv_file.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ral/Desktop/UW MSDS 2023 - 2025/Q1/DATA 511/Assignments/data511_project/ds_job_posting_cleaning.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ral/Desktop/UW%20MSDS%202023%20-%202025/Q1/DATA%20511/Assignments/data511_project/ds_job_posting_cleaning.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# Example usage:\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ral/Desktop/UW%20MSDS%202023%20-%202025/Q1/DATA%20511/Assignments/data511_project/ds_job_posting_cleaning.ipynb#W1sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39myour_csv_file.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ral/Desktop/UW%20MSDS%202023%20-%202025/Q1/DATA%20511/Assignments/data511_project/ds_job_posting_cleaning.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m result \u001b[39m=\u001b[39m count_words_in_csv(file_path)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ral/Desktop/UW%20MSDS%202023%20-%202025/Q1/DATA%20511/Assignments/data511_project/ds_job_posting_cleaning.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mThe number of words in the CSV file is: \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/ral/Desktop/UW MSDS 2023 - 2025/Q1/DATA 511/Assignments/data511_project/ds_job_posting_cleaning.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ral/Desktop/UW%20MSDS%202023%20-%202025/Q1/DATA%20511/Assignments/data511_project/ds_job_posting_cleaning.ipynb#W1sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcount_words_in_csv\u001b[39m(file_path):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ral/Desktop/UW%20MSDS%202023%20-%202025/Q1/DATA%20511/Assignments/data511_project/ds_job_posting_cleaning.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     word_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ral/Desktop/UW%20MSDS%202023%20-%202025/Q1/DATA%20511/Assignments/data511_project/ds_job_posting_cleaning.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(file_path, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m csvfile:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ral/Desktop/UW%20MSDS%202023%20-%202025/Q1/DATA%20511/Assignments/data511_project/ds_job_posting_cleaning.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         reader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mreader(csvfile)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ral/Desktop/UW%20MSDS%202023%20-%202025/Q1/DATA%20511/Assignments/data511_project/ds_job_posting_cleaning.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m reader:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_csv_file.csv'"
     ]
    }
   ],
   "source": [
    "## put it here to gauge how much using openAI would cost\n",
    "\n",
    "import csv\n",
    "\n",
    "def count_words_in_csv(file_path):\n",
    "    word_count = 0\n",
    "\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            for column in row:\n",
    "                words = column.split()\n",
    "                word_count += len(words)\n",
    "\n",
    "    return word_count\n",
    "\n",
    "# Example usage:\n",
    "file_path = 'your_csv_file.csv'\n",
    "result = count_words_in_csv(file_path)\n",
    "print(f'The number of words in the CSV file is: {result}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
